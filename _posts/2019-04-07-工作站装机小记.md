---
layout: post
title: "工作站装机小记"
date: 2019-04-07
excerpt: "双路5120+2080Ti+256G内存：科学计算与深度学习环境完整搭建"
tags: [cpp, linux, physics, python, list, machine learning]
comments: true
---

* toc
{:toc}


## 引言

最近帮组里配置了一台工作站，安装了一天的软件，这里并不会事无巨细的复述安装各种东西的过程，只是挑着把有可能出现的坑说一下。也把大体做的配置做个简单记录备忘。

## 配置

* Dell Precision T7920 Workstation [more on spec](https://i.dell.com/sites/doccontent/shared-content/data-sheets/en/Documents/Precision-7920-Tower-Spec-Sheet.pdf)
* OS: Ubuntu 18.04 LTS
* CPU: Intel Xeon Gold 5120 * 2, 2.2GHz, 56 threads in total [more on spec](https://ark.intel.com/content/www/us/en/ark/products/120474/intel-xeon-gold-5120-processor-19-25m-cache-2-20-ghz.html)
* GPU: Nvidia Geforce RTX 2080 Ti, 11GB GDDR6 [more on spec](https://www.nvidia.com/en-us/geforce/graphics-cards/rtx-2080-ti/)
* Memory: Samsung DDR4 2666MHz ECC RDIMM 256G (32G*8)  [more on spec](https://www.samsung.com/semiconductor/dram/module/M393A4K40CB2-CTD/)
* Disk: 512G Intel SSD 545s [more on spec](https://ark.intel.com/content/www/us/en/ark/products/125019/intel-ssd-545s-series-512gb-2-5in-sata-6gb-s-3d2-tlc.html) + 2T Seagate HDD, 7200 rpm [more on spec](https://www.seagate.com/www-content/datasheets/pdfs/3-5-barracudaDS1900-7-1706US-en_US.pdf)

这个配置我基本上算比较满意了，当然硬盘无论数量还是质量都一般了些，不过我们常做的那些科学计算 IO 需求不大，因此故意没有往更好配置。内存主频那么高是没用的，似乎 5120 只支持到 2400MHz。Xeon 的 6 字头 CPU 可以支持 2666 的内存频率，然而价格也更加美丽，我还是宁可多要几个核，双路 CPU，56个线程，用起来还是蛮爽的。GPU 就没什么好说的了，预算有限，就不上计算卡了。

## 安装

之所以选 Ubuntu 18.04 是因为 16.04 有点老而工作站配置的硬件又都很新，担心驱动之类的可能有问题。当然 Windows 从来就没进入过考虑范围，别的 Linux 发行版又都没有 Ubuntu 用得顺手，而且 Ubuntu 可能是驱动支持较好的 Linux 发行版了，apt 用起来也算舒服，选一些更小众的发行版的话，纯属折磨自己了。操作系统安装就不说了，随手一搜文章遍地都是，而且不安装双系统的话，几乎连坑都没有，无脑装就得了。

### 机器学习环境

机器学习环境当然先从 Nvidia 的显卡驱动开始装起，从底层驱动开始到上层的 tensorflow 为止，所装的整个软件栈一定要注意版本协调，否则分分钟不工作。对应最新的 2080Ti 显卡和最新的软件，我最终安装给出的可以正常工作的版本为：nvidia-driver-418，CUDA toolkit 10.0，cuDNN7.5，tensorflow 1.13，pytorch1.0.1。请尽量严格按照以上版本安装，不要抱着侥幸心理在用个更新的版本行不行这样作死的边缘试探。这一部分内容，主要参考了[从0开始搭建深度学习环境](https://zhuanlan.zhihu.com/p/51373519)。

下面分别提一下都有哪些坑。安装显卡驱动时，需要添加软件源，`sudo add-apt-repository ppa:graphics-drivers/ppa`。这点大家倒是都会讲，与此同时还需要注意 apt 的预发布软件源是打开的。由于该驱动很新，有些依赖只在 prerelease 的源里，这可以去 `/etc/apt/source.list` 查看，网址带有 `proposed` 的行就是。对于默认的配置，预发布似乎是打开的。但由于我手快直接换了 tuna 源的 `source.list`，而该 list 默认注释掉了预发布源，这会使得 `sudo apt install nvidia-driver-418` 时报错，去掉注释就好了。安装完驱动之后重启即可，对于有 secure boot 特性的电脑，可能还得设置硬件密码，用来每次重启时认证第三方驱动，不过建议直接进 bios 把 secure boot 关掉算了。现在输入 `nvidia-smi` 就可以看到 GPU 信息和使用情况了。

然后是装 CUDA，`nvidia-smi` 上有一栏写着 CUDA10.1，直接进官网 CUDA 下载提供的也是 CUDA10.1，但是 **千万不要安装 CUDA10.1**，该版本 CUDA 和 tensorflow 不兼容，后续安装即使最新版的 tensorflow 也会报错。而且不要指望等新版本的 tf 会兼容，tf 就有 CUDA 只兼容 9.0 不兼容之后版本号的前科。虽然 pytorch 也是写的支持 CUDA10，但是 CUDA10.1 也没问题（由此插句题外话：tensorflow 这种项目，要不是爸爸好，估计早就…）。因此需要强制搜索 CUDA10.0，在 nvidia 官网上的 CUDA archive 里可以找到对应的版本，并按照 instruction 安装即可，[参考网址](https://developer.nvidia.com/cuda-10.0-download-archive)。另一个坑，安装中需要连接的域名 `developer.download.nvidia.com` 在国内自动 301 到 `developer.download.nvidia.cn`，这域名根本就没有 DNS 解析。因此需要在 `/etc/hosts` 中添加 `128.1.83.18  developer.download.nvidia.cn` 才可正常安装 CUDA。CUDA 安装后，需要添加到系统路径，这么做是为了灵活的处理多个 CUDA 并存的情况，具体的在 `.bashrc` 中添加

```bash
export PATH=/usr/local/cuda-10.0/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
export CUDA_HOME=/usr/local/cuda
```

现在输入 `ncvv` 有信息则说明 CUDA 已经配置好了。

之后安装 cuDNN，这个需要先注册一个 Nvidia 的开发者账号，之后下载 `cuDNN Library for Linux` 选项，不要下载更具体的 for Ubuntu 之类的选项。这个我直接下载的最新的 7.4.4 版本，虽然写的支持 CUDA10.1，但是实测和 CUDA10 是兼容的。cuDNN 下载解压之后，只需把对应的头文件复制到系统路径即可，具体地说就是

```bash
sudo cp cuda/include/cudnn.h /usr/local/cuda/include
sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64
sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*
```

都安装好了之后，就可以 `pip3 install tensorflow-gpu` 来安装 tensorflow 了。至于 pytorch 还不能直接 `pip3 install torch`，而需要去 pytorch [官网](https://pytorch.org/get-started/locally/)，按照条件选择来获得应该的安装指令。具体到本机的版本配置，指令应该为

```bash
pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl
pip3 install torchvision
```

至此，整个机器学习的技术栈搭建完成，可以通过 import 这些机器学习库，调用相应的 cuda API 检查是否正常工作。

别问我为什么不用 conda，本人非常不喜欢 conda，就这样。

### 科学计算环境

在上面安装 CUDA 的过程，大量的开发相关的库，都通过 dependcy 的方式安装好了，比如著名的 `build-essential`。但是 Fortran 的编译器还没有，`apt install gfortran` 就好了。当然还是强力推荐安装一个 intel 全家桶，这样从 icc ifort 这些编译器到 mkl 这些基础库就都有了，因此推荐直接安装 Intel Parallel Studio XE 就齐活了。安装选择时可以把 intel python distribution 也选上，一次安装到位。首先需要去官网下载地址，按照 instruction 注册一个账号，才能够拿到激活码和下载地址。下载下来解压之后，运行里边 install.sh 的脚本文件，按指示即可完成 intel 全家桶的安装。实测 mkl 和 icc 确实比 openblas 和 gcc 的组合快出很多，值得花精力安装。注意到 intel 全家桶默认不写入环境变量，因此安装之后还是得注册一下环境变量，否则无法使用。整体注册的方式就是在安装位置，一般是 `/opt/intel` 中找到 `parallel_studio_xe` 文件夹中的 bin 里，直接 `source psxevars.sh` 即可。这里有几个坑，第一个就是这种方式注册的环境变量，每次只在当前 shell 生效，因此 `bash` 运行是无效的，虽然 intel 好多官方教程都是这样教的错的。同时下一次登陆，或其他用户使用时，还需要重新 `source` 来获得环境变量。如果希望 intel 这些环境变量一直生效，解决方案就是把 `source /<blah>/psxevars.sh` 这一行添加到 `/etc/profile` 里，这样每次登陆都会自动执行使得环境变量生效。其次执行该脚本后，`$PS1` 会变掉，很可能直接变为空了，因此执行完脚本，前边不再出现 `$`，会给人一种脚本卡死的错觉。为了避免这点，可以在脚本中找到修改 `$PS1` 的语句注释掉。最后，该脚本会自动激活 intel 的 python3 为默认的 python3 环境，但我暂时不希望这样，还是想保持系统的 python3 作为默认，那么就注释掉脚本里的激活 python3 虚拟环境的几行即可。最后注意，即使运行了脚本，`mpicxx` 默认连接的还是 `gcc`，为了使其连接 icc，可以直接使用 `mpiicc` 命令或者使用 `mpicxx -cxx=icc` 命令编译。

关于 intel 带的 python 版本还有一些问题，该 python 的 `sys.path` 只包括用户级的 site-package 路径，而不包括全局的路径。由于工作站的多用户特性，我大多数 python 基础 package 都是使用的 `sudo pip3` 进行的全局安装。为了使得这些 package 能够导入 intel 的 python 使用，可以编写一个 `anyname.pth` 文件放置在 intelpython3 现有的某个 `sys.path` 的文件夹内，其中内容只需要一行，指定全局 python package 的绝对路径即可，例如 `/usr/local/lib/python3.6/dist-packages`。这样每次启动 intelpython3，该路径也会自动添加到 `sys.path`，其搜索顺序和存放的原来路径的顺序保持一致。因此不要将该文件存放在过于靠前的路径里，以免导入的 numpy 等不是 intel 优化过的版本，而是默认 python 安装的版本。检验 numpy 的方法是，python 中查看 `numpy.__config__.show()`，即可了解 numpy 的底层信息。

为了有选择和对比，我也安装了 openblas，arpack，superlu 等其他线性代数库，现在看来，可能用途不大。其中 superlu 为了保持和 armadillo 要求的版本一致，我是从源码安装的，这里又有一个坑。安装 superlu 时，记得修改生成的 CMakeCache.txt，将其中的 CFLAGS 添加 `-fPIC`，之后再 `make`，不然最后安装 armadillo 时连接会报错。除了这些线性代数底层库，我还安装了 armadillo 和 eigen3 这种更适合 C++ 的线代库接口。这些库似乎 apt 源都提供，虽然我都是手动安装的。in some sense，手动安装的基础库可能性能比直接使用发布的二进制好一点。这些库在 apt 源的命名方式基本是 `lib<name>-dev`，仅供通过 apt 安装时搜索参考。其中 Eigen3，如果是通过 apt 安装的话，注意还需要额外把 header files 在文件系统向上移一层，不然头文件搜索不到（绝对是 APT 源没有考虑好的锅）。

最后又顺手装了个 mathematica，这个没什么好说的，只要你知道怎么激活，建议有能力尽量支持正版。需要注意的是，如果是多用户环境，每个用户需要单独激活。同时用户必须具有家目录，否则 mathematica 的密钥在激活后将无法写入对应路径，从而激活失败。更有趣的玩法是设定工作站作为 mathematica 的 remote kernel，如果你按照 mathematica 官方的设定方法，能连上算我输。想要能够稳定的连接，请仔细参考[该方案](https://github.com/sakra/Tunnel/blob/master/MANUAL.md)。

以上就完成了工作站大体框架和底层基础设施的安装，之后剩下的无非是 `apt` 或 `pip3` 下载需要的各种工具和 package 了。