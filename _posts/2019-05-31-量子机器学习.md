---
layout: post
title: "量子机器学习"
date: 2019-05-31
excerpt: "当机器学习遇到量子计算"
tags: [physics, algorithm, complexity theory, quantum computation, machine learning]
comments: true
---

* toc
{:toc}

## 引言

量子计算和机器学习都是热点，炙手可热那么热。两个词混在一起说就更有蹭热点的嫌疑。这要是一年前，怕是要叫区块链上的量子学习了。幸好三个词先凉了半个，我们这篇只需要讨论剩下的两个就可以交差了，是为量子机器学习。

## 意义

现阶段，将量子物理和机器学习结合，特别是尝试利用量子计算的量子硬件进行机器学习的尝试，主要有以下几个方面的价值[^Schuld2018]。

1. 早期的量子器件，也即所谓的 NISQ[^Preskill2018] (Noisy Intermediate-Scale Quantum technology) 时代的量子计算核心，可能非常适合用来**赋能机器学习**。
2. 将量子物理和机器学习结合，可能带来很多新的机器学习的想法和模型，从而**创新机器学习**。
3. 机器学习也会反过来渗透到量子计算的各个方面，从而**重新定义~~年轻人的第一次~~量子计算**。我更愿意把这一点总结为**反哺量子物理**。

### 赋能机器学习

早(xian)期(zai)的量子器件，很难实现通用量子计算，同时几乎没有量子纠错的保护，这样一种系统是很难执行一些精确的工作。比如量子计算里快有30年历史的第一 killer app，Shor algorithm。根据一些理论估算，利用 Shor algorithm 分解 2000 bits 的大合数大概需要 $$220\times10^6$$ 的物理比特[^Fowler2012]。这比现在两位数还量子纠缠很弱的比特数记录，实在是还有很遥远的距离。因此对于早期的量子器件，我们只能想办法找一些更“糙”的，有些错误问题也不大的活儿，从而在等到天荒地老分解了 2000 bit 合数的那天之前，可以宣称实现了 quantum supremacy。因此机器学习就成为了最被看好的“脏”活儿之一，毕竟其对于精度的要求没有那么高，对于错误容忍度也很大。同时其基于的各种线性代数 subroutine，很大一部分都已经有了量子的加速版本。这些 speed up 的线性代数甚至被称为 Quantum Basic Linear Algebra subroutines (qBLAS)。熟悉 BLAS 的人一定知道，这些最简单的线性代数计算的魔力，在这些底层运算上的量子加速，会赋能大量上层的应用，这就包括了几乎全部的机器学习算法，毕竟 tensor 已成为了现代机器学习搭建的基石，而整个 tensor 及其运算都是线性代数。特别是 HHL 算法[^Harrow2008]提出之后，作为一种解线性方程组加速的量子算法“模板”[^Aaronson]，极大的推动了各种量子机器学习模型的繁荣，这是因为 HHL 的模板很大程度上可以套到各式的机器学习算法之中。事实上量子线路的表达范式和神经网络的拓扑结构无疑有很多的相似之处，这也是现在很多所谓 variational circuits 研究的原因。这就是一种直接将量子线路当作神经网络的方法论。除了线性代数，优化问题也是量子计算的主场，量子退火与量子涨落使得优化目标更容易脱离局域极小。优化问题也是绝热量子计算的天然范式，D-Wave 就是这方面的代表（虽然其硬件究竟有多少量子特性依旧存疑）。

现在量子计算核心除了几乎无纠错外的另一个特征是非通用性。大部分只能执行特定的算法和任务，这种特别设计的计算核心有点类似 GPU，因此也被称为 QPU 或者叫做 ASIC (Application-Specific Integrated Circuits)。QPU 还是需要经典 CPU 辅助才可以正常工作，这被称为混合运算。更高级点的量子计算核心，可以编程实现一些不同的 circuit，这使得他们比起 CPU 更像是 FPGA 板。正如摩尔定律终结和 GPU，TPU 的兴起带来了“通用计算终结，特殊计算时代已来”的结论;从同样的视角审视，非通用的 QPU 也谈不上遗憾，恰好可以构造出很适合机器学习的 subroutine。从某种程度上说，时代在变，近30年前完成量子计算模型诞生在了通用计算机崛起和制霸的时代。那么更接地气的，也可能更有意义的 QPU 的新视角，就在这个通用计算的瓶颈期，渐渐躁动起来了。反过来看，2010年代 GPU 硬件的快速发展，带来了神经网络的复活和“变深”，从而展现出了强大的判别能力。那么量子专用器件的发展，可能使得一些只存在于理论上的机器学习方案变得可行 （比如因难于训练而不敌现代神经网络的全联接玻尔兹曼机，其本具有更好的数学解释性和更通用的生成能力）。

### 创新机器学习

正如受到物理统计模型的启发，诞生了诸如 Hopfield networks 和 Boltzmann Machine 等机器学习模型，随着量子物理和量子计算概念的不断进入和融合，也肯定会给机器学习的方法论带来“活水”。这方面现在的一些想法包括采样问题和变分线路。

量子设备可以视为一个天生的采样器，输入某个分布（波函数），经过一定的转化，测量的结果会按照一定的概率分布，从而每次测量就实现了一次按某种概率的采样。这种概率分布可能是经典计算很难高效模拟的，这就给机器学习的训练样本提供了更多可能性。同时一个量子模型本身，由于分布的描述能力更强大，可能会更快的收敛。

Variational quantum circuits 上文也已提过，基于了一种将量子线路视为神经网络，将量子门的矩阵元视为神经网络的参数，将输入波函数视为神经网络训练数据的类比。根据量子线路上量子门的结构不同，我们面对着新的量子神经网络的无限可能性，neural network zoo 的新成员将迅速增加。

另外，除了模型的推陈出新，量子物理和量子计算的世界观也可能深化人们对于机器学习这一黑箱的认识。比如对于深度学习模型和重整化群关系的探讨等等。这些我在之前的文章中也曾经讨论过。

### 重新定义量子计算

量子机器学习不只是一个量子计算和机器学习的交(ceng)叉(re)学(dian)科，它渐渐变成了量子计算的方法论本身，并开始重新定义量子计算。

从具体问题量子线路的设计和调优，到量子纠错的错误发现，监督学习和强化学习的方式和方法，正在渗透到更多量子计算的工作之中。另一方面，实验产生的大量量子物理和量子计算相关的数据，也可能成为机器学习与大数据工具大显身手的很好的平台。比如大量相关的利用机器学习来识别物相，甚至分析 STM 实验数据的工作。如果从助力量子物理的角度来看，这部分的工作无疑更多，从将玻尔兹曼机作为基态变分波函数，到探讨 tensornetwork 和神经网络的联系再到变分解码器发现序参量。更进一步的，机器学习也许可以帮助发现新的物理规律，这也本是人工智能所追求的终极目标之一。

随着经典机器学习逐渐扩大其势力范围，在很多领域渐渐取代了传统算法。那么我们也有理由相信，量子机器学习的研究本身，也可以应用到更多的领域，从而增强解决问题的通用性，减少经典算法向量子版本的迁移。也就是说，量子机器学习可能会是量子算法研究某种程度上一劳永逸的方向。

## 在做什么

上面讨论了这么多形而上的内容，这部分则稍微讨论一些具体量子机器学习领域在做的事情，虽然可能还是没有什么细节。这里的讨论基本集中在赋能和创新机器学习的部分，也就是视角放在量子计算如何帮助机器学习，而非反之（机器学习如何启发量子计算和物理）。同时当 get your hands dirty 时，就会发现，前面高谈阔论的量子机器学习，也没有那么美好和激动人心。

### quantum speed up

在意义部分，我们说过，有一些基本的线性代数算法，量子计算显示出了可能的量子加速，下表摘自[^Biamonte2017]，指出了部分机器学习算法量子加速的程度，和其对其他一些更基础算法和基础设施的依赖。比如 HHL 算法，就是用来解线性方程组的量子算法。而 qRAM 则是量子内存（还不存在）。该表选取的机器学习算法，既有量子线路上直接实现的经典学习模型，也有量子线路实现的改造过的量子模型。

<img width="80%" src="https://user-images.githubusercontent.com/35157286/58636416-d6f4b980-8322-11e9-95f5-a75d09e4df50.png">

事实上，凝视上表一会儿，你会发现量子算法领域的一个悲伤的事实——真正有加速效果的量子算法，还是90年代那两个。Amplitude amplification 基于 Grover 搜索，而 HHL 算法基于相位估计。而所谓的 phase estimation 和 Fourier transformation，Shor algorithm 本质上都是一样的（这种观点是从计算复杂度的角度来看的，几个算法做的所谓指数加速的核心都是一样的，也即量子傅立叶变换。关于本质上有几种量子加速算法的划分，可以参考[^category]）。注意改进的 HHL 算法[^Childs2015]可以基于 LCU (Linear combination of unitaries) 而不基于 phase estimation。LCU 算是比较新的一种量子底层算法。关于有用的量子算法怎么这么少的 Shor 之问，事实上依然存在。高层次的量子算法的所谓繁荣并没有带来底层算法的革新。这也是机器学习成为量子计算一个热点领域的原因，基于线性代数的机器学习，总能比较容易改造得具有某种 quantum speed up，但实际上这种加速并不是全新的和本质上的，其还是基于那几个有年头的老算法。

而且即使似乎没什么新意，那些所谓指数加速的算法上，还打了星号，表明它们所宣称的指数加速还可能存在很多漏洞。

1） 事实上，这些算法现实中到底可不可以实现指数加速还有疑虑，特别是将经典数据转化为量子波函数作为输入这一方面，究竟复杂度如何，还有待进一步考量，这被称为 input problem。虽然运算部分有加速，但数据的读取可能成为量子机器学习的瓶颈，甚至占据绝大部分时间。输出一定程度上也面临类似的问题。特别是即使一些 QRAM 的理论提议，也无法绕过构造对应 QRAM 需要的指数时间，事实上极大程度上给这些量子机器学习算法和 HHL 算法的实用性打上了问号。

2） 即使这些算法可行，对于能够实现 quantum advantage 的 HHL 算法的比特数估计超过 $$10^{25}$$[^Scherer2017]。 这说明相应的算法还要有理论上的进一步简化。也就是说，虽然从复杂度理论上来看，量子算法可能有优势，但可能由于复杂度常数太大，使得该优势发挥出的硬件规模我们根本无法构造。

3） 更别提，这些问题经典算法的理论复杂度下限还没有证明。$$P<BQP<PSPACE$$，使得证明量子计算比经典计算“快”这件事严格难于一个纯经典的数学问题，而似乎这个数学问题暂时看不到解决的迹象($$P\neq PSPACE$$)。

### quantum data

上面提到了经典大数据转化为量子输入的困难，那么也许我们可以直接用量子数据来学习。比如通过将量子模拟器和未知量子动力学系统耦合，通过调节量子模拟线路的参数，量子模拟器可以“学习”到未知的动力学演化甚至系统 Hamiltonian[^Wiebe2014]。又或者通过训练量子生成模型，可以使得模型输出的波函数“像”输入的波函数系综。但这方面可能的问题是，quantum data 似乎只局限在解决物理问题，由于业界产生的都是经典数据，这一方向应用的卖点有限。

### 量子深度学习

量子算法在用来更高效的实现深度学习这一领域，也很有前景。比如量子退火和量子涨落的热化速度更快，使得优化问题更加容易。其次很多难以模拟的分布在量子语境下可以自然产生，这些取样器在训练时，也可以摆脱一些经典模型难以训练的恶名和缓慢的经典 MCMC 采样。

这方面的主要工作既包括前神经网络时代的玻尔兹曼机的量子版本重生[^Wiebe2014b],也包括最近很热门的变分量子线路和混合计算想法融合诞生的类似神经网络的量子计算工具，基本的想法如下图所示[^Schuld2018a]。

<img width="80%" src="https://user-images.githubusercontent.com/35157286/58676016-5c12b980-8389-11e9-8812-2e29bb1027ba.png">

在这种路线图里，量子线路直接取代了靠 tensor 连接的神经网络成为更天然的通用函数器。其本质是一样的，因为所有的量子门都是一些矩阵而已，因此 QPU 的数学本质和神经网络并无二致。经典的向量输入这里换成了量子波函数，经典的标量输出这里变成了对某个量子比特的测量结果。这里的前向计算直接通过 QPU 完成，但反向传播和参数更新可以通过联动的经典计算机使用类似自动微分等方式以及巧妙的 QPU 布线外加一些量子辅助 subroutine 来解决（可能需要 LCU 算法来帮助评估梯度）。之后可以通过经典部分来更新量子线路上量子门的参数，从而反复迭代，也就是所谓的量子经典混合计算范式。

这种混合计算和将 QPU 视为经典计算的子进程，乃至整个变分线路优化的滥觞，可能是[^Peruzzo2014]，甚至这篇文章已经做出了混合计算的实验实现，装置如下图所示。

<img width="80%"  src="https://user-images.githubusercontent.com/35157286/58676946-aba6b480-838c-11e9-8ebf-fbdead390738.png">

一段话总结，量子机器学习非常火热，但事实上并不是很深刻。不过有用的东西不一定深刻，深刻的东西也不一定有用。其究竟能走多远，恐怕更多的还是要观察最近几年量子硬件的发展速度（比特数，相干时间，错误率）。如果实践证明量子摩尔定律[^Moorelaw]并不真的有效的话，整个量子计算也可能像20世纪的神经网络领域一样，进入一个或是漫长或是短暂的寒冬。

## References

[^Biamonte2017]: Quantum Machine learning, [Nature **549**, 195 (2017)](https://doi.org/10.1038/nature23474).
[^Schuld2018]: [Quantum Macine Learning 1.0](https://medium.com/xanaduai/quantum-machine-learning-1-0-76a525c8cf69).
[^Preskill2018]: Quantum Computing in the NISQ era and beyond, [Quantum **2**, 79 (2018)](https://doi.org/10.22331/q-2018-08-06-79).
[^Fowler2012]: Surface codes: Toward practical large-scale quantum computation, [Phys. Rev. A **86**, 032324 (2012)](https://doi.org/10.1103/PhysRevA.86.032324).
[^Childs2015]: Quantum algorithm for systems of linear equations with exponentially improved dependence on precision, [arXiv:1511.02306](https://arxiv.org/abs/1511.02306).
[^Scherer2017]: Concrete resource analysis of the quantum linear system algorithm used to compute the electromagnetic scattering cross section of a 2D target, [arXiv:1505.06552](https://arxiv.org/abs/1505.06552).
[^Wiebe2014]: Hamiltonian Learning and Certification Using Quantum Resources, [Phys, Rev. Lett. **112**, 190501](https://doi.org/10.1103/PhysRevLett.112.190501).
[^Wiebe2014b]: Quantum Deep Learning, [arXiv:1412.3489](https://arxiv.org/abs/1412.3489).
[^Schuld2018a]: Circuit-centric quantum classifiers, [arXiv:1804.00633](https://arxiv.org/abs/1804.00633).
[^Peruzzo2014]: A variational eigenvalue solver on a photonic quantum processor, [Nat. Comm. **5**, 4213 (2014)](https://www.nature.com/articles/ncomms5213).
[^Moorelaw]: [Does Moore's law apply to quantum computing?](https://quantumcomputing.stackexchange.com/questions/1803/does-moores-law-apply-to-quantum-computing)
[^Aaronson]: [Quantum Machine Learning Algorithms: Read the Fine Print](https://scottaaronson.com/papers/qml.pdf).
[^Harrow2008]: Quantum algorithm for solving linear systems of equations, [arXiv:0811.3171](https://arxiv.org/abs/0811.3171).
[^category]: [Are there any known quantum algorithms that clearly fall outside a few narrow classes?](https://mathoverflow.net/questions/33597/are-there-any-known-quantum-algorithms-that-clearly-fall-outside-a-few-narrow-cl)

